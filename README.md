# Titanic

The **Titanic+Tutorial - OL.ipynb** file was just me playing around with the sample dataset on Kaggle. Not finished with it yet. For the most part, I followed [hamelg's blog](http://hamelg.blogspot.com/2015/12/python-for-data-analysis-part-30-random.html) as a preliminary exploration of the data. 

**Titanic Tutorial Pt II** included a mixture of [Deependra Singh Jhala's work](https://www.kaggle.com/dsjhala/titanic-starting-with-kaggle-81-6-random-forest) that he posted in a kernel, using Python to impute data and implement the Random Forest Tree algorithm. Submitted the preliminary predictions on Kaggle and got an accuracy score of 0.72727. Could definitely use some improvement. If I have time, I'd like to go back and visit some of the other kernels that incorporated stacked models.
